# -*- coding: utf-8 -*-
"""hw3_nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OUKI4MHzYAoK9m2PHpgLm7XQIN57HO6w

<html>
<h2 dir='rtl'>
در این قسمت قصد داریم که روش n-gram را پیاده سازی کنیم.
</h2>
</html>

<html>
<h4 dir='rtl'>
در ابتدا کتابخانه ی nltk را نصب میکنیم، سپس بقیه موارد مورد نیاز را ایمپورت میکنیم.
 </h4>
</html>
"""

!pip install nltk

import nltk
from nltk.util import ngrams
from collections import Counter
from collections import defaultdict
nltk.download('punkt')

from google.colab import drive
drive.mount('/content/drive')

"""<html>
<h4 dir='rtl'>
با کمک دیتاست مان را می خوانیم و در ادامه از آن استفاده می کنیم.
 </h4>
</html>
"""

# Path to the text file
file_path = '/content/drive/MyDrive/Test/neda.txt'

text = ''

with open(file_path, 'r', encoding='utf-8') as file:
    text = file.read().splitlines()

"""<html>
<h4 dir='rtl'>
به کمک کتابخانه nltk متن مان را میخوانیم و آن‌ها را به توکن های n تایی تقسیم بندی می کنیم.
 </h4>
</html>
"""

def make_ngram_model(n, ngram_list):
  
  # Create a list of tokens from the text
  tokens = nltk.word_tokenize(' '.join(text))  # Assuming 'text' contains the list of lines from the text file

  # Generate n-grams
  ngram_list = list(ngrams(tokens, n))

  return ngram_list

"""<html>
<h4 dir='rtl'>
در تابع زیر قصد داریم که دیکشنری درست کنیم برای اینکه تعداد تکرار هر کدام از تاپل ها را در متن مان به دست بیاوریم و احتمال شان را نسبت به کل تاپل های ساخته شده محاسبه نماییم.
 </h4>
</html>
"""

def make_dictionary_for_ngram_model(ngram_list):

  # Create a dictionary with default values of 0
  tuple_dict = defaultdict(int)

  # Count the occurrences of each tuple
  for tpl in ngram_list:
      tuple_dict[tpl] += 1

  # Divide all values by all number of the unique touple
  number_of_unique_touple = len(tuple_dict)
  for tpl in tuple_dict:
      tuple_dict[tpl] /= number_of_unique_touple

  return tuple_dict

"""<html>
<h4 dir='rtl'>
در ادامه احتمالات را برای تاپل های سه تایی مشاهده میکنید.
 </h4>
</html>
"""

three_gram_list = []
three_gram_list = make_ngram_model(3, three_gram_list)
tuple_dict_for_three_gram = {}
tuple_dict_for_three_gram = make_dictionary_for_ngram_model(three_gram_list)
# Print the resulting dictionary for 3 gram
for tpl, count in tuple_dict_for_three_gram.items():
    print(tpl, count)

#The work of this function is that it takes a sentence as input and also takes
# a number which is n and separates the words of the sentence from n to n.

def divide_sentence(sentence, num):
    words = sentence.split()
    result = []
    
    for i in range(len(words) - num + 1):
        group = tuple(words[i:i+num])
        result.append(group)
    
    return result

"""<html>
<h4 dir='rtl'>
در تابع زیر میخواهیم با کمک احتمال هایی که برای هر یک از تاپل های موجود به دست آوردیم، بیاییم و برای جمله ای که کاربر به ورودی ما داده است، احتمال آن جمله را بر اساس تاپل های تشکیل شده به دست بیاوریم.
لازم به ذکر است که اگر تاپل مان در دیکشنری ساخته شده وجود داشت احتمالش را در حاصل نهایی مان ضرب می کنیم ولی اگر وجود نداشت عدد بسیار کوچکی را در حاصل نهایی مان ضرب میکنیم. این کار را برای این خاطره انجام می‌دهیم که اگر تاپلی وجود نداشت عدد صفر در حاصل نهایی مان ضرب نشود که کل حاصل صفر شود.
 </h4>
</html>
"""

# This function takes a list of words that are divided into n and calculates
# their probability in the most data that is based on its model.
# If our created tuples are available in the dataset, it will come and
# multiply the values together to calculate the score of the sentence 
#we gave to the model. If this tuple is not available in the data, 
#we will replace it with a very small number that does not affect the final result.

def calc_score_n_gram(word_n_groups , tuple_dict_for_n_gram):

  scores_dict = {}

  for group in word_n_groups:
    score = 1
    if group in tuple_dict_for_n_gram:
      score *= tuple_dict_for_n_gram[group]
    else:
      score = 0.000000000000000000000000000001
    scores_dict[group] = score

  final_score = 1
  for value in scores_dict.values():
    final_score *= value

  return final_score

sentence = 'من به مدرسه میروم '
number = 3

word_three_groups = divide_sentence(sentence, number)
print(word_three_groups)

"""<html>
<h4 dir='rtl'>
حاصلی که شما مشاهده می کنید حاصلضرب تمامی احتمال های سه تایی برای جمله ورودی مان است.
 </h4>
</html>
"""

three_gram_score = 0
three_gram_score = calc_score_n_gram(word_three_groups , tuple_dict_for_three_gram)
three_gram_score

two_gram_list = []
two_gram_list = make_ngram_model(2, two_gram_list)
tuple_dict_for_two_gram = {}
tuple_dict_for_two_gram = make_dictionary_for_ngram_model(two_gram_list)
# Print the resulting dictionary for bi-gram
for tpl, count in tuple_dict_for_two_gram.items():
    print(tpl, count)

"""<html>
<h4 dir='rtl'>
برای همان جمله ورودی می خواهیم مجدداً روش ان گرم را حساب کنیم اما این بار ان  برابر با ۲ است.
 </h4>
</html>
"""

sentence = 'من به مدرسه میروم '
number = 2

word_two_groups = divide_sentence(sentence, number)
print(word_two_groups)

two_gram_score = 0
two_gram_score = calc_score_n_gram(word_two_groups , tuple_dict_for_two_gram)
two_gram_score